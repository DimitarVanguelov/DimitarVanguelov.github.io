{
  "hash": "94862aa94181d9859a9a6a402bb8b349",
  "result": {
    "markdown": "---\ntitle: \"Generating Fake People with Julia\"\n# author: \"Dimitar Vanguelov\"\ndate: \"2023-02-22\"\n---\n\nIn a [recent MotherDuck blog post](https://motherduck.com/blog/python-faker-duckdb-exploration/), \nthe author generated 1 billion fake people records using Python in order to analyze the data \nwith DuckDB. I suspect the point of the article was to showcase how awesome `duckdb` is at \nhandling large amounts of local data (I personally didn't need the extra convincing, I was \nalready a fan), but it did spend the majority of its time explaining the data generation process.\n\nOne of the most interesting tidbits from the article to me was (emphasis mine):\n\n> I used the GNU Parallel technique discussed above with a **hefty m6i.32xlarge instance** on \nAmazon EC2, though generated a billion people in 1k parquet files. This **took about 2 hours to \ngenerate**.\n\nYikes, that's a lot of firepower! In case you're [too lazy to look it up](https://instances.vantage.sh/aws/ec2/m6i.32xlarge), \nthat machine comes with 128 vCPUs and 512 GiB RAM, and costs about $6 an hour. So pretty hefty \nindeed.\n\nNow, being a Julia user -- there is something in us that just compels us to want to make things \ngo faster, and it's not clear if we're drawn to Julia because it's an innate quality in us, or \nif programming in Julia breaks our brains and makes us want to optimize... like everything -- \nI immediately nerd-sniped myself into seeing if I could speed up this fake generation of people \nrecords, not on some beefy instance, but on my plain old laptop.\n\nThe results were initially disappointing, as I'll explain below, but in the end I did get that \nnice speed-up I was looking for.\n\n\n## The Details\n\nRefer to the original post for the full details, but I'll go over the basic details here. A \n`person` record consists of the following randomly generated fields:\n```\n- id\n- first_name\n- last_name\n- email\n- company\n- phone\n```\n\nUsing the Python [Faker](https://faker.readthedocs.io/en/master/) library to generate the \ndata and [GNU Parallel](https://www.gnu.org/software/parallel/) to parallelize the operation, \nthe author created 1,000 parquet files with 1 million records each before populating a \n`duckdb` database for further analysis.\n\nIn this post, we'll explore Julia's own \n[Faker.jl](https://github.com/neomatrixcode/Faker.jl) package, and how to leverage the various, \nbuilt-in capabilities Julia has for concurrency and parallelism.\n\n\n## Julia: First Attempt\n\nAs mentioned, Julia has its own Faker library. Using it is as simple as:\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code}\nusing Faker\n\nFaker.first_name()\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n\"Heath\"\n```\n:::\n:::\n\n\nInstead of putting all the fields in a dictionary, I created a struct instead:\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code}\nstruct Person\n    id::String\n    first_name::String\n    last_name::String\n    email::String\n    company::String\n    phone::String\nend\n```\n:::\n\n\nAside from being a natural thing to do in Julia, this ended up being a really handy vehicle \nfor populating a DataFrame, as we'll see in a moment.\n\nIn order to construct the `Person` object, we have the following function, which is essentially \nthe same as in the Python version in the original post:\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code}\nfunction get_person()\n    person = Person(\n        Faker.random_int(min=1000, max=9999999999999),\n        Faker.first_name(),\n        Faker.last_name(),\n        Faker.email(),\n        Faker.company(),\n        Faker.phone_number()\n    )\n    return person\nend\n\nget_person()\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\nPerson(\"531318646699\", \"Pearline\", \"Roberts\", \"Hettinger.Tory@bl.org\", \"Wiegand LLC\", \"107-936-9117 x69192\")\n```\n:::\n:::\n\n\nThis approach clearly suffers from the same deficiency as the original in that the generated \nemail address bears absolutely no semblance to the generated first and last names ðŸ˜‚. But \nthat's ok, we're just making up data for mocking and testing purposes anyhow.\n\nTo create an array of `Person`s, we can use a comprehension:\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code}\nlist_of_five = [get_person() for _ in 1:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n5-element Vector{Person}:\n Person(\"7458738230968\", \"Carina\", \"Bergnaum\", \"Tilda.Hettinger@hgar.biz\", \"Ortiz-D'Amore\", \"310.246.4443\")\n Person(\"7458344071827\", \"Paul\", \"Sporer\", \"Eliz.Stoltenberg@hotmail.com\", \"Bins and Sons\", \"1-795-159-6632\")\n Person(\"2925283190195\", \"Gabriel\", \"Stoltenberg\", \"Mamie78@hotmail.com\", \"Funk-Jaskolski\", \"827-315-2192\")\n Person(\"7964768739855\", \"Theresia\", \"Raynor\", \"pReinger@yahoo.com\", \"Hayes, Murazik and Huels\", \"897-004-9036 x61245\")\n Person(\"8650989609058\", \"Jed\", \"Lakin\", \"Enoch72@sbag.co\", \"Dare-Braun\", \"(646) 706-8481 x3264\")\n```\n:::\n:::\n\n\nNotice how we get a `Vector` of `Person`s... this is partially where that cool thing happens. \nPlacing that vector in a `DataFrame` constructor creates a dataframe object for us without any \nhassle at all:\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code}\nusing DataFrames\n\ndf = DataFrame(list_of_five)\n```\n:::\n\n\n```\n5Ã—6 DataFrame\n Row â”‚ id             first_name  last_name  email                      company                         phone                 \n     â”‚ String         String      String     String                     String                          String                \nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚ 9006394878384  Treva       Friesen    Funk.Roy@ar.name           Boehm-Roberts                   624-581-8651 x27099\n   2 â”‚ 4911678414881  Demetra     Wiza       TBechtelar@hotmail.com     Fritsch-Ebert                   504.840.2004 x016\n   3 â”‚ 5665302809885  Felipa      Bradtke    Hermann.Maurice@gmail.com  Lockman, Wintheiser and Cronin  530.779.9959 x685\n   4 â”‚ 2166373345058  Janie       Berge      Carita38@hotmail.com       Shields-Schowalter              1-855-593-7414 x54562\n   5 â”‚ 5865747761410  Landon      McKenzie   Kihn.Lauri@was.co          Lueilwitz-Daniel                (296) 989-2137 x8766\n```\n\nThat's pretty neat!\n\nAnyhow, with our basic functionality all set up, it's time to do some light benchmarking to \nget a sense of how this code will perform. I started off small by generating only a 100,000 \nrecords:\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code}\n@time [get_person() for _ in 1:100_000] |> DataFrame;\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 65.911398 seconds (51.68 M allocations: 2.484 GiB, 1.61% gc time, 0.15% compilation time: 30% of which was recompilation)\n```\n:::\n:::\n\n\nOof, that result is not very comforting -- taking a minute plus just for 100,000 records does \nnot bode well. Assuming linear scaling, it would take 65 * 10_000 seconds, or roughly 180 hours \nto run the full thing ðŸ˜°.\n\nAt this point, I'm thinking we can speed things up a bit by using multi-threading. But figuring \nout the right syntax for creating an array and then populating it with data using threading \nappeared a bit clunky. Luckily there exists the ThreadsX.jl package that allows us to use \ncomprehensions for such things, specifically by using `ThreadsX.collect` over our comprehension:\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code}\nusing ThreadsX\n\n@time ThreadsX.collect(get_person() for _ in 1:100_000) |> DataFrame;\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 11.608021 seconds (54.56 M allocations: 2.674 GiB, 6.03% gc time, 6.52% compilation time)\n```\n:::\n:::\n\n\nOk so that's a little better, but running 12 threads and getting a 5-6x speed-up is not that \ngreat, but, more importantly, by our linear scaling logic, the full 1 billion record run \nwould take approximately 30 hours on my laptop. Just to generate the data, nevermind \nserializing it to disk.\n\nDespite knowing it's a losing battle, I wrote a function to generate all the data and save it \nas parquet files, just like in the original post:\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code}\nusing Parquet2: writefile\n\nfunction save_the_people(num_people, num_files)\n    @sync for i in 1:num_files\n        file_num = string(i, pad=ndigits(num_files))\n        file_loc = \"./data/outfile_$(file_num).parquet\"\n        df = ThreadsX.collect(get_person() for _ in 1:num_people) |> DataFrame\n        @async writefile(file_loc, df; compression_codec=:snappy)\n    end\nend\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nsave_the_people (generic function with 1 method)\n```\n:::\n:::\n\n\n## Appendix\n\nThe code in this post was run with Julia 1.8.5 and the following package versions:\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code}\nusing Pkg\n\nPkg.status([\"Faker\", \"DataFrames\", \"Parquet2\", \"ThreadsX\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStatus `~/.julia/environments/v1.8/Project.toml`\n  [a93c6f00] DataFrames v1.5.0\n  [0efc519c] Faker v0.3.5\n  [98572fba] Parquet2 v0.2.9\n  [ac1d9e8a] ThreadsX v0.1.11\n```\n:::\n:::\n\n\nAdditional hardware and software info:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code}\nversioninfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nJulia Version 1.8.5\nCommit 17cfb8e65ea (2023-01-08 06:45 UTC)\nPlatform Info:\n  OS: Linux (x86_64-linux-gnu)\n  CPU: 16 Ã— AMD Ryzen 7 PRO 4750U with Radeon Graphics\n  WORD_SIZE: 64\n  LIBM: libopenlibm\n  LLVM: libLLVM-13.0.1 (ORCJIT, znver2)\n  Threads: 16 on 16 virtual cores\nEnvironment:\n  JULIA_EDITOR = code\n  JULIA_NUM_THREADS = auto\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}